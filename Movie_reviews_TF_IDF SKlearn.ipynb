{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9fc86914-828d-4a46-ba7f-c1f4980e1cc9",
    "_uuid": "89d41aa529dd673b83937281bec04f0a75af8b54"
   },
   "source": [
    "# Movie Sentiment Analysis\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6b1ab40-34da-4645-98c4-4b61c97895f6",
    "_uuid": "0259bd59e4fad41ffd78aa5a510a83ef07daab7f",
    "collapsed": true
   },
   "source": [
    " 拿到数据首先读入拿到数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "a89760f4-9075-42be-b4c4-c8c87d175c88",
    "_uuid": "4429a082ddabcb23261daec29ee1ae9e68ba2a2e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train = pd.read_csv('labeledTrainData.tsv', delimiter=\"\\t\")\n",
    "test = pd.read_csv('testData.tsv', delimiter=\"\\t\")\n",
    "train.head()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "76be376a-0c66-4001-ac99-9b968ce62781",
    "_uuid": "bc7497787d1d19eee918fec0faabe29669a8b3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "print (train.shape)\n",
    "print (test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "708ea854-0c20-4ac0-97b7-90075d8f63c4",
    "_uuid": "ad1c1cf6085fdf9d83c34c68b324f1c73e710315"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re  #正则表达式\n",
    "\n",
    "def review_preprocessing(review):\n",
    "    #只保留英文单词\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    \n",
    "    #变成小写\n",
    "    words = review_text.lower()\n",
    "    \n",
    "    return(words)\n",
    "\n",
    "# 把训练集的文本和标注分开\n",
    "\n",
    "y_train=train.sentiment\n",
    "y_test=train.sentiment\n",
    "\n",
    "reviews=train.review\n",
    "X_train=[]\n",
    "\n",
    "for review in reviews:\n",
    "    words=review_preprocessing(review)\n",
    "    X_train.append(words)\n",
    "    \n",
    "  \n",
    "X_train=np.array(X_train)\n",
    "\n",
    "\n",
    "reviews_test=test.review\n",
    "X_test=[]\n",
    "\n",
    "for review in reviews_test:\n",
    "    words=review_preprocessing(review)\n",
    "    X_test.append(words)\n",
    "X_test=np.array(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test[0],'------',y_test[0],'------',X_train[0],'------',y_train[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "2514583c-d410-4dd8-9ce2-db907d4e3750",
    "_uuid": "83cd36c185194d6513246af09afb76e20241b380"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer=CountVectorizer()\n",
    "\n",
    "\n",
    "\n",
    "X_train_occurrence=vectorizer.fit_transform(X_train)\n",
    "X_valid_occurrence=vectorizer.transform(X_valid)\n",
    "X_test_occurrence= vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tf-idf\n",
    "tfidf=TfidfVectorizer()\n",
    "X_train_tfidf=tfidf.fit_transform(X_train)\n",
    "X_valid_tfidf=tfidf.transform(X_valid)\n",
    "X_test_tfidf=tfidf.transform(X_test)\n",
    "\n",
    "features=tfidf.get_feature_names()\n",
    "#print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多项式朴素贝叶斯\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "classifier=MultinomialNB()\n",
    "\n",
    "classifier.fit(X_train_occurrence,y_train)\n",
    "prediction_valid=classifier.predict(X_valid_occurrence)\n",
    "prediction=classifier.predict(X_test_occurrence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "a50a42b3-659d-470d-bef6-cc96d4b87935",
    "_uuid": "1df60d0c5595dbef07726f082c0c25336be8f56c"
   },
   "outputs": [],
   "source": [
    "tfidf_classifier=MultinomialNB()\n",
    "tfidf_classifier.fit(X_train_tfidf,y_train)\n",
    "tfidf_valid=tfidf_classifier.predict(X_valid_tfidf)\n",
    "tfidf_prediction=tfidf_classifier.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      2481\n",
      "           1       0.87      0.82      0.84      2519\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.85      0.85      0.85      5000\n",
      "weighted avg       0.85      0.85      0.85      5000\n",
      "\n",
      "[[2175  306]\n",
      " [ 453 2066]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print (classification_report(y_valid, prediction_valid))\n",
    "print (confusion_matrix(y_valid, prediction_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86      2481\n",
      "           1       0.88      0.84      0.86      2519\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n",
      "[[2189  292]\n",
      " [ 399 2120]]\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_valid, tfidf_valid))\n",
    "print (confusion_matrix(y_valid, tfidf_valid))\n",
    "\n",
    "\n",
    "#ok. 看来TFIDF 比普通的NB 好一点点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "92e53d2f-36a2-4563-94be-bd4180d91ce6",
    "_uuid": "f87c65946b352d663140864a1ee81adc7b3c94dd"
   },
   "outputs": [],
   "source": [
    "# 把结果保存到csv文件中，并进行提交: https://www.kaggle.com/c/word2vec-nlp-tutorial/leaderboard\n",
    "df = pd.DataFrame({\"id\": test['id'],\"sentiment\": tfidf_prediction})\n",
    "df.to_csv('submission.csv',index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
